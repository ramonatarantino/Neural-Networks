{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks for Data Science Applications\n",
        "## Homework 1: Saliency maps for interpretability\n",
        "\n",
        "**Name**: Ramona Tarantino\n",
        "\n",
        "**Matricola**: 2082006\n",
        "\n",
        "> ‚úç Upload the completed notebook **before 10/11/2023 at 23:59** on the Google Classroom page."
      ],
      "metadata": {
        "id": "BwfXT98e5hQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V6Ph3UT44Xo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To ensure reproducible results (as much as possible)\n",
        "tf.keras.utils.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "GkYGd_WY_2nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "\n",
        "Neural networks are powerful tools, but they are **black-boxes**, meaning that it is difficult to provide human-understandable explanations on what they are doing. The field of **explanaibility** is concerned with finding algorithms for achieving this. In this homework, you will be guided in implementing some basic explanaibility algorithms (**saliency maps**), which is an instructive way of playing with the TensorFlow autodiff framework.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. The homework is divided into four mandatory exercises (**5 points in total**), and a few optional exercises. Optional exercises are provided if you like the topic and would like to explore more; you are free to ignore them or complete as many as you want. I will not grade them but I might provide feedback for especially nice solutions.\n",
        "2. Completing the homework successfully will remove 1 exercise from the end-of-term homework.\n",
        "3. If your grade does not satisfy you, you are also free to complete the full EoT homework to recover it.\n",
        "3. The grade can be kept for the entire academic year (up to October 2024).\n",
        "\n",
        "**IMPORTANT - read carefully before starting**:\n",
        "\n",
        "> üü® *External material*: if you use any external material or inspiration for the code, reference it *explicitly* in the corresponding cell. For the textual descriptions, copy-paste *is not allowed*. <ins>Not following these two points is an immediate 0 mark</ins>.\n",
        "\n",
        "> üîµ *Grammar*: for the textual descriptions, I will remove points for too many grammatical or textual errors. Please try to be precise and provide nice-to-read descriptions, like if you were writing a report.\n",
        "\n",
        "> üü• *Vectorization and TensorFlow*: the homework must be done _fully in TensorFlow_ and vectorizing the code as much as possible (e.g., do not loop explicitly over the batch dimension).\n",
        "\n",
        "> üü™ *Math*: you can also use LaTeX in Markdown if you need to write equations or if you need generic math notation."
      ],
      "metadata": {
        "id": "BmzKI83R0uYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warmup: Data loading\n",
        "\n",
        "For this homework, you can select any **tabular dataset** that you like, for either classification or regression. A few repositories that you can look at:\n",
        "\n",
        "1. The catalog of [TensorFlow Datasets](https://www.tensorflow.org/datasets/).\n",
        "2. The [Kaggle catalog](https://www.kaggle.com/data). For downloading data from Kaggle on Google Colab, you will need to [load your Kaggle authentication token](https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb).\n",
        "3. The [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php).\n",
        "4. The [ü§ó HuggingFace Datasets](https://huggingface.co/docs/datasets/) repository.\n",
        "\n",
        "You are not bound to these; any open repository is okay. The choice of dataset will not influence the mark."
      ],
      "metadata": {
        "id": "SE7pCfZK2G5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úç **DESCRIPTION OF THE CODE**\n",
        "\n",
        "*Provide a small description of the dataset below (e.g., source, task, bibliographic reference if necessary...), both as text and in the comments of the code.*\n",
        "\n",
        "**TODO**: add description here (1-2 paragraphs)."
      ],
      "metadata": {
        "id": "fzThDtr4VJ5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Iris dataset is a multivariate dataset introduced by the British statistician and biologist Ronald Fisher in his 1936 paper. The dataset consists of 150 samples from three species of Iris (Iris setosa, Iris virginica, and Iris versicolor) stored in a 150x4 numpy.ndarray. Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
        "\n",
        "\n",
        "\n",
        "The task associated with this dataset is to classify the samples into one of the three Iris species based on the attribute measurements. This dataset is widely used for educational purposes in the fields of machine learning and statistics due to its simplicity and the fact that it is a well-understood problem. The dataset is freely available in the UCI Machine Learning Repository, and it is also included with the scikit-learn machine learning library for Python.\n"
      ],
      "metadata": {
        "id": "d-AN9Xmn0teu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to one-hot encoding for neural network\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "k2f_yB_W0lkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1: Train a neural network model (1 point)\n",
        "\n",
        "Define, train, and test a neural network for the provided dataset.\n",
        "\n",
        "‚òù You are free to make any modelling choice (e.g., activation function, normalization layers, etc.), provided the result makes sense.\n",
        "\n",
        "‚úÖ **Completion requirement**: print on screen the test accuracy of the network. Additional comments and visualizations are also appreciated."
      ],
      "metadata": {
        "id": "5Myy-Aq33upU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: define a suitable neural network.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(8, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "sUb8Sa3z1NSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c05c44d-14c9-41e6-bab7-92a01c84ac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139 (556.00 Byte)\n",
            "Trainable params: 139 (556.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Model Type:**\n",
        "   - The model is a Sequential model. In a Sequential model, layers are added one at a time, and each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "2. **Layers:**\n",
        "   - **Dense Layer (Hidden Layer 1):**\n",
        "     - Type: Dense\n",
        "     - Output Shape: (None, 8)\n",
        "     - Number of Parameters: 40\n",
        "     - Activation Function: Default activation (often ReLU if not specified)\n",
        "     - Description: This is the first hidden layer with 8 neurons. Each neuron is fully connected to the input, and the output shape is (None, 8). The layer has 40 parameters (weights and biases).\n",
        "\n",
        "   - **Dense Layer (Hidden Layer 2):**\n",
        "     - Type: Dense\n",
        "     - Output Shape: (None, 8)\n",
        "     - Number of Parameters: 72\n",
        "     - Activation Function: Default activation\n",
        "     - Description: This is the second hidden layer with 8 neurons. It takes the output from the first hidden layer as input and produces an output shape of (None, 8). The layer has 72 parameters.\n",
        "\n",
        "   - **Dense Layer (Output Layer):**\n",
        "     - Type: Dense\n",
        "     - Output Shape: (None, 3)\n",
        "     - Number of Parameters: 27\n",
        "     - Activation Function: Default activation\n",
        "     - Description: This is the output layer with 3 neurons, representing the number of classes in a classification task. The output shape is (None, 3), and it has 27 parameters.\n",
        "\n",
        "3. **Total Parameters:**\n",
        "   - The model has a total of 139 parameters (weights and biases). Parameters are the variables the model learns from the training data.\n",
        "\n",
        "4. **Trainable Parameters:**\n",
        "   - All 139 parameters are trainable. During the training process, the values of these parameters are updated to minimize the loss function.\n",
        "\n",
        "5. **Non-trainable Parameters:**\n",
        "   - There are no non-trainable parameters in this model. Non-trainable parameters are typically associated with layers like BatchNormalization, which have parameters that are not updated during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "71NlaEAqfP-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: train the neural network.\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train, y_train_one_hot, epochs=50, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yckj4Hv1Q8B",
        "outputId": "e8860129-0698-4746-f1de-3617f106e0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 3s 157ms/step - loss: 1.0279 - accuracy: 0.6250 - val_loss: 1.0074 - val_accuracy: 0.7500\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.0202 - accuracy: 0.6458 - val_loss: 0.9999 - val_accuracy: 0.7500\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.0135 - accuracy: 0.6458 - val_loss: 0.9923 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 1.0062 - accuracy: 0.6667 - val_loss: 0.9848 - val_accuracy: 0.7917\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9989 - accuracy: 0.6875 - val_loss: 0.9772 - val_accuracy: 0.7917\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.9920 - accuracy: 0.7188 - val_loss: 0.9691 - val_accuracy: 0.7917\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.9848 - accuracy: 0.7708 - val_loss: 0.9608 - val_accuracy: 0.7917\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9773 - accuracy: 0.7917 - val_loss: 0.9525 - val_accuracy: 0.7917\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.9700 - accuracy: 0.7917 - val_loss: 0.9440 - val_accuracy: 0.7917\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.9621 - accuracy: 0.7812 - val_loss: 0.9354 - val_accuracy: 0.7917\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.9543 - accuracy: 0.7812 - val_loss: 0.9266 - val_accuracy: 0.7917\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9462 - accuracy: 0.7812 - val_loss: 0.9175 - val_accuracy: 0.8750\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.9379 - accuracy: 0.7812 - val_loss: 0.9084 - val_accuracy: 0.8750\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.9297 - accuracy: 0.7812 - val_loss: 0.8991 - val_accuracy: 0.8750\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.9210 - accuracy: 0.7812 - val_loss: 0.8895 - val_accuracy: 0.8750\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.9123 - accuracy: 0.7812 - val_loss: 0.8801 - val_accuracy: 0.8750\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9034 - accuracy: 0.7708 - val_loss: 0.8706 - val_accuracy: 0.8750\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8944 - accuracy: 0.7708 - val_loss: 0.8607 - val_accuracy: 0.8750\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.8854 - accuracy: 0.7917 - val_loss: 0.8510 - val_accuracy: 0.8750\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.8761 - accuracy: 0.8021 - val_loss: 0.8413 - val_accuracy: 0.8750\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8668 - accuracy: 0.8021 - val_loss: 0.8317 - val_accuracy: 0.8750\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.8573 - accuracy: 0.8021 - val_loss: 0.8219 - val_accuracy: 0.8750\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.8479 - accuracy: 0.8021 - val_loss: 0.8120 - val_accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.8379 - accuracy: 0.7917 - val_loss: 0.8023 - val_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.8281 - accuracy: 0.7917 - val_loss: 0.7925 - val_accuracy: 0.8750\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8183 - accuracy: 0.7917 - val_loss: 0.7826 - val_accuracy: 0.8750\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.8086 - accuracy: 0.7917 - val_loss: 0.7726 - val_accuracy: 0.8750\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.7983 - accuracy: 0.8021 - val_loss: 0.7624 - val_accuracy: 0.8750\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.7884 - accuracy: 0.8021 - val_loss: 0.7526 - val_accuracy: 0.8750\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.7783 - accuracy: 0.8021 - val_loss: 0.7428 - val_accuracy: 0.8750\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.7687 - accuracy: 0.8021 - val_loss: 0.7327 - val_accuracy: 0.8750\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.7587 - accuracy: 0.7917 - val_loss: 0.7226 - val_accuracy: 0.8750\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.7486 - accuracy: 0.7917 - val_loss: 0.7123 - val_accuracy: 0.8750\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.7385 - accuracy: 0.7917 - val_loss: 0.7023 - val_accuracy: 0.8750\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.7285 - accuracy: 0.7917 - val_loss: 0.6923 - val_accuracy: 0.8750\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7183 - accuracy: 0.7917 - val_loss: 0.6827 - val_accuracy: 0.8750\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.7083 - accuracy: 0.8021 - val_loss: 0.6732 - val_accuracy: 0.8750\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.6985 - accuracy: 0.8021 - val_loss: 0.6634 - val_accuracy: 0.8750\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6882 - accuracy: 0.8021 - val_loss: 0.6536 - val_accuracy: 0.8750\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6783 - accuracy: 0.8021 - val_loss: 0.6437 - val_accuracy: 0.8750\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.6686 - accuracy: 0.8021 - val_loss: 0.6342 - val_accuracy: 0.8750\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6589 - accuracy: 0.8021 - val_loss: 0.6248 - val_accuracy: 0.9167\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.6489 - accuracy: 0.8021 - val_loss: 0.6158 - val_accuracy: 0.9167\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6395 - accuracy: 0.8021 - val_loss: 0.6070 - val_accuracy: 0.9167\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6301 - accuracy: 0.8125 - val_loss: 0.5984 - val_accuracy: 0.9167\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6208 - accuracy: 0.8125 - val_loss: 0.5903 - val_accuracy: 0.9167\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.6117 - accuracy: 0.8125 - val_loss: 0.5821 - val_accuracy: 0.9583\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6029 - accuracy: 0.8125 - val_loss: 0.5741 - val_accuracy: 0.9583\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5938 - accuracy: 0.8125 - val_loss: 0.5670 - val_accuracy: 0.9583\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.5855 - accuracy: 0.8125 - val_loss: 0.5600 - val_accuracy: 0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: test the neural network and print the result on screen.\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
        "print(f\"Test accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fGSsGga1XlW",
        "outputId": "4a833235-ba45-455a-ba70-98aa9dbe58a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2733 - accuracy: 0.9667\n",
            "Test accuracy: 0.9666666388511658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Computing a vanilla saliency map (1 points)\n",
        "\n",
        "> Before starting, I suggest you read [1] as a warm-up. This is one of the first papers that tried to apply this kind of techniques to modern neural networks.\n",
        "\n",
        "What do we mean by explainability? Consider the neural network $f(\\cdot)$ you just trained, and a prediction $\\hat{y} = f(x)$ we want to analyze. **Feature attribution** methods try to assign a weight $w_i$ to each input feature $x_i$, to understand which parts of the input have contributed the most to the explanation.\n",
        "\n",
        "The simplest feature attribution technique, called **vanilla saliency map**, simply computes the gradient at that point:\n",
        "\n",
        "$$\n",
        "  S(x) = \\left\\lvert \\frac{\\partial f_c(x)}{\\partial x} \\right\\rvert\n",
        "$$\n",
        "\n",
        "where  $c$ is the index corresponding to the predicted class.\n",
        "\n",
        "‚úÖ **Completion requirement**: Take any point from your test dataset, and compute a saliency map using `tf.GradientTape`. Check the weight to see if you can find anything to \"interpret\". **Note**: I am not evaluating how nice / good the explanation is, only the code."
      ],
      "metadata": {
        "id": "0i1Jr0mQ7lRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Take an element from your test set and compute the saliency map\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Choose a sample from the test set\n",
        "test_sample = X_test[0]\n",
        "test_sample = np.expand_dims(test_sample, axis=0)  # Expand dimensions to match model input\n",
        "\n",
        "# Cast the test sample to a TensorFlow tensor\n",
        "test_sample_tensor = tf.convert_to_tensor(test_sample, dtype=tf.float32)\n",
        "\n",
        "# Watch the input pixels to compute gradient with respect to\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(test_sample_tensor)\n",
        "\n",
        "    # Compute the model's prediction for this sample\n",
        "    prediction = model(test_sample_tensor)\n",
        "    predicted_class_idx = tf.argmax(prediction[0]).numpy()\n",
        "\n",
        "    # Get the output corresponding to the predicted class\n",
        "    predicted_class_output = prediction[:, predicted_class_idx]\n",
        "\n",
        "# Compute the gradient of the output with respect to the input\n",
        "saliency_map = tape.gradient(predicted_class_output, test_sample_tensor).numpy()\n",
        "\n",
        "\n",
        "print(\"Saliency Map for the chosen sample:\")\n",
        "print(saliency_map)\n"
      ],
      "metadata": {
        "id": "WGeQDlEpJ-3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f464568-c424-4599-921c-cbb52322da3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saliency Map for the chosen sample:\n",
            "[[ 0.04512196 -0.05686454  0.06894968 -0.01811148]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Check the saliency map to analyze the result. What can you say about the map?"
      ],
      "metadata": {
        "id": "rkc0Q7gfgOkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The saliency map is a one-dimensional array with four values, each corresponding to the gradient of the output with respect to each of the four features of the dataset.\n",
        "\n",
        "- The first value corresponds to the gradient with respect to the first feature. A negative value indicates that an increase in this feature would decrease the model's output for the predicted class, meaning this feature contributes inversely to the model's decision for the specific class.\n",
        "\n",
        "- The second value is negative and larger in magnitude than the first, suggesting this feature has a stronger inverse relationship with the model's prediction for the chosen class.\n",
        "\n",
        "- The third value is positive, indicating that increasing this feature would increase the output for the predicted class. This feature positively influences the model's decision for the class it predicted.\n",
        "\n",
        "- The fourth value again shows a negative gradient, indicating an inverse relationship with the predicted class output.\n",
        "\n",
        "Overall, the saliency map suggests that the second feature has the strongest inverse effect on the model's decision for the predicted class. The third feature appears to be the most positively influential. However, since the values are quite small, it implies that the changes in the input features would result in relatively small changes in the output prediction for the class."
      ],
      "metadata": {
        "id": "b_njRdMjf_C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3: Advanced saliency maps (1 point)\n",
        "\n",
        "> For this exercise, you can read [2] for an overview on the limits of vanilla saliency maps and a description of SmoothGrad.\n",
        "\n",
        "Saliency maps have several issues: most notably, they suffer from noise and they are not stable to small changes in the input or in the model (try running again the training and interpreting the same point). Many methods have been proposed to overcome this.\n",
        "\n",
        "**[SmoothGrad](https://arxiv.org/abs/1706.03825)**, for example, computes multiple saliency maps from noisy versions of the input:\n",
        "\n",
        "$$\n",
        "  \\text{SmoothGrad}(x) = \\frac{1}{n}\\sum_{i=1}^n S(x + \\varepsilon_i), \\;\\; \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2I)\n",
        "$$\n",
        "\n",
        "where $\\varepsilon$ is a vector of the same shape as $x$, whose values are sampled from a normal distribution with zero mean and small variance.\n",
        "\n",
        "üü© **Completion requirement**: Implement the SmoothGrad procedure for the same point. Has the explanation improved? Bonus points if you can avoid running a for-loop, and by calling the gradient operation a single time.\n"
      ],
      "metadata": {
        "id": "XXUhR5ZH9PKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Take an element from your test set and compute SmoothGrad. Check the results and compare with respect to the previous exercise.\n",
        "\n",
        "\n",
        "sample_point = X_test[np.random.choice(len(X_test))]\n",
        "\n",
        "n = 50  # The number of samples for SmoothGrad\n",
        "sigma = 0.1  # The standard deviation for the noise\n",
        "\n",
        "# Create a batch of noise samples\n",
        "noise = np.random.normal(0, sigma, (n, sample_point.shape[0]))\n",
        "\n",
        "# Add the noise to the sample point and create a batch of noisy samples\n",
        "noisy_samples = sample_point + noise\n",
        "\n",
        "\n",
        "# Convert the numpy array to a TensorFlow tensor\n",
        "noisy_samples_tensor = tf.convert_to_tensor(noisy_samples, dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    tape.watch(noisy_samples_tensor)\n",
        "\n",
        "    # Predict the classes of the noisy samples\n",
        "    predictions = model(noisy_samples_tensor)\n",
        "\n",
        "    # Take the class with the highest probability from the original prediction\n",
        "    # for the sample point\n",
        "    predicted_class = tf.argmax(model(tf.expand_dims(sample_point, 0)), axis=1).numpy()[0]\n",
        "\n",
        "    # Gather the logits for the predicted class\n",
        "    logits_for_class = predictions[:, predicted_class]\n",
        "\n",
        "# Compute the gradients\n",
        "gradients = tape.gradient(logits_for_class, noisy_samples_tensor)\n",
        "\n",
        "# Compute the average of the gradients to get the SmoothGrad\n",
        "smoothgrad = tf.reduce_mean(gradients, axis=0)\n",
        "\n",
        "print(smoothgrad)\n"
      ],
      "metadata": {
        "id": "rJZBZUFA6POv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f41267c-5f13-461f-ee44-573e5307e321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0.09972796 -0.04282816 -0.14913218  0.34133148], shape=(4,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check the results and compare with with respect to the previous:**\n",
        "\n",
        "The magnitude of the gradients in the SmoothGrad saliency map seems to be generally larger. This can be a result of the noise reduction that is part of the SmoothGrad technique, which tends to highlight the areas of the input that consistently have a strong influence on the model's output.\n",
        "The sign of the gradients has changed for some of the features. For example, the third feature had a positive gradient in the original map but has a negative one in the SmoothGrad map. This may indicate that the influence of this feature on the model's decision is more complex and the original saliency map might have been affected by noise.\n",
        "The SmoothGrad method provide a clearer picture of feature importance by averaging the gradients over many noisy instances of the input. Therefore, we would expect the SmoothGrad map to provide a more reliable indication of which features are actually important for the model's prediction.\n",
        "The last feature shows a significantly larger positive gradient in the SmoothGrad saliency map compared to the original. This suggests that, once the noise is reduced, this feature may have a stronger positive influence on the model's decision than initially indicated.\n"
      ],
      "metadata": {
        "id": "F99SAKnQ4Kfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4: Global explanations (2 points)\n",
        "\n",
        "The previous exercises are examples of **local** explanations, where we try to interpret a single prediction of the network. Sometimes we are interested in **global** explanations, that try to find common patterns of behaviour. Suppose we have a dataset $\\mathcal{T} = \\left\\{x_i\\right\\}$ of examples, we can compute some approximate global measure of influence by averaging their saliency:\n",
        "\n",
        "$$\n",
        "\\text{GlobalSaliency} = \\frac{1}{n} \\sum_i S(x_i)\n",
        "$$\n",
        "\n",
        "To make this exercise more interesting, we will split it into 3 parts.\n",
        "\n",
        "**Exercise 4.1**: write a function to compute in parallel the saliency for multiple examples. Note that the resulting matrix $S$ will have shape $(n, d)$, where $n$ is the number of examples and $d$ the size of the input, which is the Jacobian of the network. Try to write the function by avoiding for-loops and multiple tapes, using the [proper tools from TensorFlow](https://www.tensorflow.org/guide/advanced_autodiff)."
      ],
      "metadata": {
        "id": "pIFUonMOY-Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the required function, possibly avoding for-loops.\n",
        "def compute_saliency(model, data):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(data)\n",
        "        predictions = model(data)\n",
        "    gradients = tape.gradient(predictions, data)\n",
        "    saliency = tf.abs(gradients)\n",
        "    return saliency\n",
        "\n",
        "\n",
        "\n",
        "data = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "compute_saliency(model, data)"
      ],
      "metadata": {
        "id": "nJdQ6nbp-rIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8deda15-8e68-4856-ebba-f6bcfea32bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 4), dtype=float32, numpy=\n",
              "array([[3.6744876e-08, 5.4710096e-08, 6.7799533e-08, 3.1568206e-09],\n",
              "       [1.7571600e-09, 3.1856364e-09, 1.2546431e-10, 4.4862078e-09],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [3.5356096e-10, 4.4869930e-09, 1.7738390e-09, 3.1316574e-09],\n",
              "       [4.4176209e-09, 2.9462106e-08, 4.6605209e-08, 2.3678489e-08],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [1.8172318e-10, 3.0022889e-09, 3.2279945e-09, 3.9222621e-09],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [2.2097199e-10, 2.8043248e-09, 1.1086312e-09, 1.9572539e-09],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [1.3940561e-08, 3.0406738e-08, 2.7947186e-08, 1.2916944e-08],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [3.9344197e-08, 6.2905528e-08, 7.7098683e-08, 4.0330588e-09],\n",
              "       [9.1036712e-10, 1.1553343e-08, 4.5673731e-09, 8.0635543e-09],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [3.7258111e-08, 6.8185457e-08, 8.3465679e-08, 1.8735609e-08],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4.2**: write a function to compute the global saliency and try to explain the results."
      ],
      "metadata": {
        "id": "As4lalRBcMHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the required function.\n",
        "def compute_global_saliency(model, data):\n",
        "    # Compute the saliency for each example\n",
        "    saliency = compute_saliency(model, data)\n",
        "\n",
        "    # Compute the global saliency by averaging across all examples\n",
        "    global_saliency = tf.reduce_mean(saliency, axis=0)\n",
        "    return global_saliency\n",
        "\n",
        "data = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "compute_global_saliency(model, data)\n"
      ],
      "metadata": {
        "id": "O08JfYJQcS1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed27d6fc-a1cd-419b-b278-c553e057c08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
              "array([4.5043054e-09, 9.0234176e-09, 1.0457321e-08, 2.8027283e-09],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each element in the array represents the average saliency value for the corresponding feature across all examples.\n",
        "The values are very small (on the order of 1e-09), indicating that, on average, each feature has a relatively low impact on the model's predictions across the test examples"
      ],
      "metadata": {
        "id": "Lf2eH7u83ATR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4.3**: note that a linear model $f(x) = w^\\top x + b$ is an example of an *intrinsically* interpretable  model, since the weights $w$ can be checked to analyze the global saliency of each feature (see [3])."
      ],
      "metadata": {
        "id": "D2j6pi3XcX86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Compare the results you obtained before with a simpler linear model.\n",
        "def compare_saliency_with_linear_model(complex_model_saliency, linear_model_weights):\n",
        "    # The saliency for a linear model is the absolute value of its weights\n",
        "    linear_model_saliency = tf.abs(linear_model_weights)\n",
        "\n",
        "    # Compare the two saliencies\n",
        "    print(\"Complex Model Saliency:\\n\", complex_model_saliency)\n",
        "    print(\"Linear Model Saliency:\\n\", linear_model_saliency)\n",
        "\n",
        "    difference = tf.reduce_mean(tf.abs(complex_model_saliency - linear_model_saliency))\n",
        "    return difference\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vjnDxBNicom1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "complex_model_saliency = compute_global_saliency(model, data)\n",
        "\n",
        "# Obtain the weights\n",
        "linear_model_weights = linear_model.coef_\n",
        "linear_model_weights = tf.convert_to_tensor(linear_model_weights, dtype=tf.float32)\n",
        "\n",
        "# Compure the differences\n",
        "difference = compare_saliency_with_linear_model(complex_model_saliency, linear_model_weights)\n",
        "\n",
        "print(\"Difference in Saliency between Complex Model and Linear Model:\", difference.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eovN09U33THg",
        "outputId": "71901c9d-fd7a-4830-fac3-aea0794c6787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex Model Saliency:\n",
            " tf.Tensor([4.5043054e-09 9.0234176e-09 1.0457321e-08 2.8027283e-09], shape=(4,), dtype=float32)\n",
            "Linear Model Saliency:\n",
            " tf.Tensor([0.09543703 0.02673551 0.44483158 0.41023025], shape=(4,), dtype=float32)\n",
            "Difference in Saliency between Complex Model and Linear Model: 0.24430859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional exercises and parting words\n",
        "\n",
        "> ‚ö† Explainability is a complex topic, with multiple issues arising from the over-abundance of techniques, their instability, etc. While an interesting research topic to pursue, never use blindly these techniques in high-stake applications!\n",
        "\n",
        "These exercises were just a brief and short introduction to the topic of explainability. Below you can find some additional exercises to tackle if you are interested. Remember that these are not part of your grade, but I am happy to provide feedback if they are of interest to you.\n",
        "\n",
        "1. There are dozens of possible variations on feature attribution methods, which may or may not provide better results (see [4] for a benchmarking and this nice [Distill blog post](https://distill.pub/2020/attribution-baselines/)). **[Integrated Gradients](https://arxiv.org/abs/1703.01365)** are an interesting example, where the saliency is integrated over a path ranging from an empty input to the true input. Try implementing integrated gradients.\n",
        "2. **Data attribution** methods are a different class of explanation methods, which try to predict what points in the dataset where most influential to a given prediction (e.g., a picture of a cat will be especially influential on similar pictures). One example of such methods is TracIn [5], which stores checkpoints of the model during training and evaluates the correlation of the gradients. Try to implement TracIn or any other metric of data influence.\n",
        "3. A recent line of research tries to use large language models (e.g., ChatGPT) to explain other models (e.g., see [Language models can explain neurons in language models](https://openai.com/research/language-models-can-explain-neurons-in-language-models)). If you have access to an LLM, you can try it! Take a specific neuron in the model, and collect the activation for multiple examples. Provide these activations to the LLM, and prompt it to provide a human-understandable explanation. What is the result?"
      ],
      "metadata": {
        "id": "Pp2K2VXGdAtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final checklist\n",
        "\n",
        "1. Carefully check all code. Insert comments when needed. Search for \"TODO\" to see if you forgot something.\n",
        "2. Run everything one final time. *Please do not send me notebooks with errors or cells that are not working.*\n",
        "3. Upload the completed notebook **before 10/11/2023 23:59** on the Google Classrom page."
      ],
      "metadata": {
        "id": "GIyU8c7lh4Ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bibliography\n",
        "\n",
        "[1] Simonyan, K., Vedaldi, A. and Zisserman, A., 2013. [Deep inside convolutional networks: Visualising image classification models and saliency maps](https://arxiv.org/abs/1312.6034). arXiv preprint arXiv:1312.6034.\n",
        "\n",
        "[2] Smilkov, D., Thorat, N., Kim, B., Vi√©gas, F. and Wattenberg, M., 2017. [SmoothGrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825). arXiv preprint arXiv:1706.03825.\n",
        "\n",
        "[3] Rudin, C., 2019. [Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead](https://www.nature.com/articles/s42256-019-0048-x). Nature Machine Intelligence, 1(5), pp. 206-215.\n",
        "\n",
        "[4] Nguyen, G., Kim, D. and Nguyen, A., 2021. [The effectiveness of feature attribution methods and its correlation with automatic evaluation scores](https://proceedings.neurips.cc/paper/2021/hash/de043a5e421240eb846da8effe472ff1-Abstract.html). Advances in Neural Information Processing Systems, 34, pp.26422-26436.\n",
        "\n",
        "[5] Pruthi, G., Liu, F., Kale, S. and Sundararajan, M., 2020. [Estimating training data influence by tracing gradient descent](https://proceedings.neurips.cc/paper/2020/hash/e6385d39ec9394f2f3a354d9d2b88eec-Abstract.html). Advances in Neural Information Processing Systems, 33, pp. 19920-19930."
      ],
      "metadata": {
        "id": "YCfzjQOIe6CQ"
      }
    }
  ]
}