{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjTTay3NTM7v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets, utils\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Callback per salvare il modello con la migliore accuratezza di validazione\n",
        "checkpoint_cb = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor='val_accuracy')\n",
        "\n",
        "# Callback per fermare l'addestramento se non c'Ã¨ miglioramento in 'patience' epoche\n",
        "early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_accuracy')"
      ],
      "metadata": {
        "id": "rEQ9Ut1BTbaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, utils\n",
        "\n",
        "# Load Fashion MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Upscale images from 28x28 to 32x32 and add 3 channels\n",
        "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
        "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
        "x_train = np.stack((x_train,)*3, axis=-1)\n",
        "x_test = np.stack((x_test,)*3, axis=-1)\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)\n",
        "\n",
        "input_shape = x_train.shape[1:]  # Now (32, 32, 3)\n"
      ],
      "metadata": {
        "id": "UwmCOA_NUSqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAABZ9xTUToe",
        "outputId": "fd5976d5-1852-46a1-8590-7eec06b796bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### resnet + adapters"
      ],
      "metadata": {
        "id": "mSOCeXIJgISW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Select a Pre-trained Model"
      ],
      "metadata": {
        "id": "NXSpbI0VTm6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the base ResNet50 model without the top layer\n",
        "base_resnet_model = ResNet50(include_top=False, weights=None, input_shape=(32, 32, 3))\n",
        "\n",
        "# Add new top layers\n",
        "x = base_resnet_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# This is the model we will train\n",
        "base_model = Model(inputs=base_resnet_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_base_model = base_model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWpEe-oiVQSe",
        "outputId": "73f2b1dd-3882-4001-cc27-0dbbb25d7ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 125s 47ms/step - loss: 0.7728 - accuracy: 0.7614 - val_loss: 0.5970 - val_accuracy: 0.7856\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.5700 - accuracy: 0.8231 - val_loss: 0.6966 - val_accuracy: 0.7570\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.6006 - accuracy: 0.8112 - val_loss: 4.8914 - val_accuracy: 0.5094\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 85s 46ms/step - loss: 0.4209 - accuracy: 0.8565 - val_loss: 0.4069 - val_accuracy: 0.8519\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.4237 - accuracy: 0.8539 - val_loss: 0.4478 - val_accuracy: 0.8323\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 83s 44ms/step - loss: 0.3467 - accuracy: 0.8775 - val_loss: 0.3833 - val_accuracy: 0.8562\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.3846 - accuracy: 0.8703 - val_loss: 0.4579 - val_accuracy: 0.8388\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.3513 - accuracy: 0.8797 - val_loss: 0.3030 - val_accuracy: 0.8909\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.2985 - accuracy: 0.8946 - val_loss: 0.3053 - val_accuracy: 0.8900\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.2707 - accuracy: 0.9031 - val_loss: 0.4213 - val_accuracy: 0.8559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_loss, base_model_accuracy = base_model.evaluate(x_test, y_test)\n",
        "print(f\"Base ResNet50 Model Accuracy: {base_model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxmaumi5aPtv",
        "outputId": "812cc833-f1fb-42f1-fe1b-d2d69fdb0485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4213 - accuracy: 0.8559\n",
            "Base ResNet50 Model Accuracy: 0.85589998960495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Design Adapters\n"
      ],
      "metadata": {
        "id": "tctNt6qVTrXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use ResNet50 for Feature Extraction: Freeze the layers of ResNet50 and use it to extract features from the images.\n",
        "\n",
        "Add Custom Head with Adapters: Create a custom head with one or more adapter layers and a final classification layer."
      ],
      "metadata": {
        "id": "h7cBlSu5VTyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Conv2D, ReLU, Add, Flatten\n",
        "\n",
        "# Load the base ResNet50 model\n",
        "base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "def create_adapter_module(x, reduction_factor=16):\n",
        "    \"\"\"Creates an adapter module.\"\"\"\n",
        "    # Reduce channels\n",
        "    reduced = Conv2D(x.shape[-1] // reduction_factor, (1, 1), activation='relu')(x)\n",
        "    # Expand channels back to original\n",
        "    expanded = Conv2D(x.shape[-1], (1, 1))(reduced)\n",
        "    # Add back to original input\n",
        "    out = Add()([x, expanded])\n",
        "    return out\n",
        "\n",
        "# Add custom head to the base model\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = create_adapter_module(x)  # Add adapter module\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)  # Flatten the output for the Dense layer\n",
        "outputs = Dense(10, activation='softmax')(x)  # Final classification layer\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60SQ0Hm9U6mZ",
        "outputId": "f72aef55-fce1-4d71-ea40-9096b67b85f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 31s 13ms/step - loss: 0.8598 - accuracy: 0.6760 - val_loss: 0.6824 - val_accuracy: 0.7348\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.6817 - accuracy: 0.7420 - val_loss: 0.6584 - val_accuracy: 0.7453\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.6442 - accuracy: 0.7561 - val_loss: 0.6164 - val_accuracy: 0.7709\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.6222 - accuracy: 0.7650 - val_loss: 0.6410 - val_accuracy: 0.7568\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.6040 - accuracy: 0.7739 - val_loss: 0.5986 - val_accuracy: 0.7715\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.5860 - accuracy: 0.7796 - val_loss: 0.5920 - val_accuracy: 0.7793\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.5720 - accuracy: 0.7865 - val_loss: 0.6616 - val_accuracy: 0.7557\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.5665 - accuracy: 0.7871 - val_loss: 0.5537 - val_accuracy: 0.7941\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.5621 - accuracy: 0.7882 - val_loss: 0.5438 - val_accuracy: 0.7988\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.5471 - accuracy: 0.7953 - val_loss: 0.5972 - val_accuracy: 0.7758\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a2539ddcd30>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Fine tuned Model Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US1ol2-5aTan",
        "outputId": "dcd6a511-ca72-4581-a902-233400e4bb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 0.5972 - accuracy: 0.7758\n",
            "Fine tuned Model Accuracy: 0.7757999897003174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### resnet + lora"
      ],
      "metadata": {
        "id": "wuoee99KZ-LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRADense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, rank, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.rank = rank\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Initialize weights to match input dimension and number of units\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer='random_normal', trainable=False, name='w')  # Adjusted to match input dimension\n",
        "        self.b = self.add_weight(shape=(self.units,), initializer='zeros', trainable=True, name='b')\n",
        "\n",
        "        # LoRA parameters, A is [units, rank] and B is [rank, units]\n",
        "        self.lora_A = self.add_weight(shape=(self.units, self.rank), initializer='random_normal', trainable=True, name='lora_A')\n",
        "        self.lora_B = self.add_weight(shape=(self.rank, input_shape[-1]), initializer='random_normal', trainable=True, name='lora_B')  # Adjusted to match input dimension\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Standard dense layer calculation with adjusted weight dimensions\n",
        "        z = tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "        # LoRA update, note the multiplication order for lora_B and inputs\n",
        "        lora_update = tf.matmul(self.lora_A, tf.matmul(self.lora_B, tf.transpose(inputs))) * adaptation_rate  # Adjusted multiplication order\n",
        "        lora_update = tf.transpose(lora_update)  # Transpose back to match the original dimensions\n",
        "\n",
        "        # Apply the LoRA update to the original output\n",
        "        z += lora_update\n",
        "\n",
        "        # Apply activation function if any\n",
        "        if self.activation is not None:\n",
        "            z = self.activation(z)\n",
        "        return z\n"
      ],
      "metadata": {
        "id": "XsUxVm95Z9oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNet(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze the model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prlmVEvWat4E",
        "outputId": "c65d20ee-6784-4b9a-c03b-c47129165e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(base_model.output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBOnonFEayTv",
        "outputId": "d12c731a-762b-4b82-9b80-0cfe46089edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1, 1, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add new top layers to the base model with LoRA\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = LoRADense(128, 8, activation='relu')(x)  # Example LoRA layer\n",
        "outputs = Dense(10, activation='softmax')(x)  # Final classification layer for Fashion MNIST\n",
        "\n",
        "# Create and compile the model\n",
        "model_lora = Model(inputs, outputs)\n",
        "model_lora.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_lora.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9ZvtRtMahSz",
        "outputId": "41349fbf-df8f-4fad-b204-39a7bb8c0fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 1.8433 - accuracy: 0.3661 - val_loss: 1.6783 - val_accuracy: 0.4194\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 1.6210 - accuracy: 0.4391 - val_loss: 1.5948 - val_accuracy: 0.4566\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 1.5631 - accuracy: 0.4590 - val_loss: 1.5527 - val_accuracy: 0.4618\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 1.5328 - accuracy: 0.4674 - val_loss: 1.5343 - val_accuracy: 0.4661\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 1.5126 - accuracy: 0.4745 - val_loss: 1.5192 - val_accuracy: 0.4700\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 1.4986 - accuracy: 0.4778 - val_loss: 1.5017 - val_accuracy: 0.4785\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 1.4873 - accuracy: 0.4807 - val_loss: 1.4954 - val_accuracy: 0.4795\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 1.4774 - accuracy: 0.4839 - val_loss: 1.4941 - val_accuracy: 0.4769\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 1.4699 - accuracy: 0.4875 - val_loss: 1.4817 - val_accuracy: 0.4819\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 1.4630 - accuracy: 0.4887 - val_loss: 1.4710 - val_accuracy: 0.4923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a2440325600>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lora_loss, model_lora_accuracy = model_lora.evaluate(x_test, y_test)\n",
        "print(f\"Fine tuned Model with lora Accuracy: {model_lora_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWGIGcihcHgf",
        "outputId": "98c1cf87-19a2-4c3f-f9e7-30457020e364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 1.4710 - accuracy: 0.4923\n",
            "Fine tuned Model with lora Accuracy: 0.49230000376701355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semplice CNN invece di ResNet50\n",
        "(funziona meglio)"
      ],
      "metadata": {
        "id": "w49zkTuWbx5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model_cnn = models.Sequential([\n",
        "    # Layer 1: Convolutional layer\n",
        "    layers.Conv2D(8, (3, 3), activation='relu', input_shape=(32, 32, 3)),  # Ridotto a 8 filtri\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flattening the 3D output to 1D\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Dense layer for classification, ridotto la dimensione a 16\n",
        "    layers.Dense(16, activation='relu'),  # Ridotta la dimensione a 16\n",
        "\n",
        "    # Output layer\n",
        "    layers.Dense(10, activation='softmax')  # 10 classi per Fashion MNIST\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "N87noE1qb1jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "MBK6H155cEL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_model_cnn = model_cnn.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-3IJf55cUmp",
        "outputId": "ec0b3470-957d-43e2-fa04-b5d7848b10b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4926 - accuracy: 0.8271 - val_loss: 0.3711 - val_accuracy: 0.8691\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3317 - accuracy: 0.8827 - val_loss: 0.3437 - val_accuracy: 0.8760\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2955 - accuracy: 0.8949 - val_loss: 0.3114 - val_accuracy: 0.8893\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2721 - accuracy: 0.9041 - val_loss: 0.3153 - val_accuracy: 0.8878\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2549 - accuracy: 0.9086 - val_loss: 0.3105 - val_accuracy: 0.8909\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2390 - accuracy: 0.9143 - val_loss: 0.2973 - val_accuracy: 0.8934\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2253 - accuracy: 0.9173 - val_loss: 0.2888 - val_accuracy: 0.8993\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2132 - accuracy: 0.9232 - val_loss: 0.2906 - val_accuracy: 0.9005\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2033 - accuracy: 0.9258 - val_loss: 0.3062 - val_accuracy: 0.8960\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1946 - accuracy: 0.9288 - val_loss: 0.3043 - val_accuracy: 0.8980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn_loss, model_cnn_accuracy = model_cnn.evaluate(x_test, y_test)\n",
        "print(f\"CNN Accuracy: {model_cnn_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEJLEHufc3gs",
        "outputId": "9973f5fb-efef-4427-bdcf-36520472775d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3043 - accuracy: 0.8980\n",
            "CNN Accuracy: 0.8980000019073486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRADense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, rank, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.rank = rank\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Original Dense parameters\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer='random_normal', trainable=False, name='w')\n",
        "        self.b = self.add_weight(shape=(self.units,), initializer='zeros', trainable=True, name='b')\n",
        "\n",
        "        # LoRA parameters\n",
        "        self.lora_A = self.add_weight(shape=(input_shape[-1], self.rank), initializer='random_normal', trainable=True, name='lora_A')\n",
        "        self.lora_B = self.add_weight(shape=(self.rank, self.units), initializer='random_normal', trainable=True, name='lora_B')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Standard dense layer calculation\n",
        "        z = tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "        # LoRA update\n",
        "        lora_update = tf.matmul(tf.matmul(inputs, self.lora_A), self.lora_B)\n",
        "\n",
        "        # Apply the LoRA update to the original output\n",
        "        z += lora_update\n",
        "\n",
        "        # Apply activation function if any\n",
        "        if self.activation is not None:\n",
        "            z = self.activation(z)\n",
        "        return z\n",
        "\n",
        "# Modifica dell'architettura del modello\n",
        "model_lora2 = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    LoRADense(32, rank=4, activation='relu'),  # LoRA layer invece del Dense layer normale\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilazione e addestramento come prima\n",
        "model_lora2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model_lora2.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZp29_vOdV07",
        "outputId": "fb030117-5752-41c9-c53b-bfb99073d765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.6098 - accuracy: 0.7816 - val_loss: 0.4698 - val_accuracy: 0.8252\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4133 - accuracy: 0.8494 - val_loss: 0.4114 - val_accuracy: 0.8459\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3667 - accuracy: 0.8688 - val_loss: 0.3824 - val_accuracy: 0.8614\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3366 - accuracy: 0.8784 - val_loss: 0.3695 - val_accuracy: 0.8664\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3141 - accuracy: 0.8873 - val_loss: 0.3474 - val_accuracy: 0.8756\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2983 - accuracy: 0.8920 - val_loss: 0.3378 - val_accuracy: 0.8802\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2871 - accuracy: 0.8967 - val_loss: 0.3235 - val_accuracy: 0.8859\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2766 - accuracy: 0.9001 - val_loss: 0.3272 - val_accuracy: 0.8873\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2664 - accuracy: 0.9035 - val_loss: 0.3187 - val_accuracy: 0.8895\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2583 - accuracy: 0.9062 - val_loss: 0.3170 - val_accuracy: 0.8924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lora2_loss, model_lora2_accuracy = model_lora2.evaluate(x_test, y_test)\n",
        "print(f\"CNN + Lora Accuracy: {model_lora2_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfCxtCWReFbf",
        "outputId": "e6030c13-e182-4062-9527-d4d2671ef7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8924\n",
            "CNN + Lora Accuracy: 0.8924000263214111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fine tuning selettivo:"
      ],
      "metadata": {
        "id": "p44Z-dqCePyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_lora2.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "cj0bvu7heSIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scongela il layer LoRADense\n",
        "model_lora2.layers[-2].trainable = True  # Assumendo che il LoRADense sia il penultimo layer\n",
        "\n",
        "# Opzionale: Scongela anche l'ultimo layer Dense se vuoi affinarne i pesi\n",
        "model_lora2.layers[-1].trainable = True\n"
      ],
      "metadata": {
        "id": "kLvI3MwWeUlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lora2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ScDId_LQeaMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lora2.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRtyzPGLekw0",
        "outputId": "dcf5a95d-a093-4055-a58e-c209212c5135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 40s 4ms/step - loss: 0.2478 - accuracy: 0.9098 - val_loss: 0.3093 - val_accuracy: 0.8914\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2412 - accuracy: 0.9140 - val_loss: 0.3073 - val_accuracy: 0.8935\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2360 - accuracy: 0.9155 - val_loss: 0.3142 - val_accuracy: 0.8942\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2326 - accuracy: 0.9165 - val_loss: 0.3106 - val_accuracy: 0.8934\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2284 - accuracy: 0.9183 - val_loss: 0.3086 - val_accuracy: 0.8957\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2235 - accuracy: 0.9199 - val_loss: 0.3286 - val_accuracy: 0.8871\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2212 - accuracy: 0.9203 - val_loss: 0.3147 - val_accuracy: 0.8950\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2178 - accuracy: 0.9208 - val_loss: 0.3149 - val_accuracy: 0.8917\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2147 - accuracy: 0.9225 - val_loss: 0.3190 - val_accuracy: 0.8934\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2118 - accuracy: 0.9236 - val_loss: 0.3064 - val_accuracy: 0.8995\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a2434192440>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lora2_loss, model_lora2_accuracy = model_lora2.evaluate(x_test, y_test)\n",
        "print(f\"CNN + Lora Accuracy: {model_lora2_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykxfvVHPfBsD",
        "outputId": "9956b927-e441-4104-b963-61b626f44b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.8995\n",
            "CNN + Lora Accuracy: 0.8995000123977661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merging models (resnet + cnn(lora))"
      ],
      "metadata": {
        "id": "_45viwDDgxOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lora2.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLf1rkbFgzUR",
        "outputId": "86d2b8c3-ff3b-4cc3-93b1-10f6c79d4bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.layers.convolutional.conv2d.Conv2D at 0x7a243421c0a0>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7a243421c2b0>,\n",
              " <keras.src.layers.reshaping.flatten.Flatten at 0x7a243421cca0>,\n",
              " <__main__.LoRADense at 0x7a243421c9d0>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a243421c760>]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_resnet_model.layers"
      ],
      "metadata": {
        "id": "9VCDZRzMhAHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Per base_resnet_model, estraiamo le caratteristiche dal penultimo layer Add\n",
        "resnet_features = Model(inputs=base_resnet_model.input,\n",
        "                        outputs=base_resnet_model.layers[-3].output)  # Penultimo layer Add\n",
        "\n",
        "# Per model_lora2, estraiamo le caratteristiche dal layer LoRADense\n",
        "lora_features = Model(inputs=model_lora2.input,\n",
        "                      outputs=model_lora2.layers[-2].output)  # Layer LoRADense\n"
      ],
      "metadata": {
        "id": "jd8SvNmshhHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "# Input layer\n",
        "input_layer = tf.keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# Ottieni le caratteristiche dai due modelli\n",
        "resnet_output = resnet_features(input_layer)\n",
        "lora_output = lora_features(input_layer)\n",
        "\n",
        "# Appiattisci l'output di ResNet per renderlo compatibile\n",
        "resnet_output_flat = Flatten()(resnet_output)\n",
        "\n",
        "# Combina le caratteristiche appiattite di ResNet con quelle di LoRADense\n",
        "combined_features = Concatenate()([resnet_output_flat, lora_output])\n",
        "\n",
        "# Aggiungi un layer denso per la classificazione finale\n",
        "x = layers.Dense(256, activation='relu')(combined_features)\n",
        "x = layers.Dropout(0.5)(x)  # Regolarizzazione\n",
        "output_layer = layers.Dense(10, activation='softmax')(x)  # 10 classi per Fashion MNIST\n",
        "\n",
        "# Modello combinato\n",
        "combined_model = Model(inputs=input_layer, outputs=output_layer)\n"
      ],
      "metadata": {
        "id": "Xq8MKKbbiZja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model.compile(optimizer='adam',\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Addestra il modello combinato sui tuoi dati Fashion MNIST\n",
        "history_combined = combined_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPE633snizdd",
        "outputId": "0305d571-766e-475e-b54e-9853eb51ac46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 118s 47ms/step - loss: 0.4054 - accuracy: 0.8805 - val_loss: 0.3384 - val_accuracy: 0.8885\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.3436 - accuracy: 0.8886 - val_loss: 0.3362 - val_accuracy: 0.8877\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.3535 - accuracy: 0.8856 - val_loss: 0.3559 - val_accuracy: 0.8876\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.3233 - accuracy: 0.8893 - val_loss: 0.3253 - val_accuracy: 0.8917\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.3164 - accuracy: 0.8922 - val_loss: 0.3604 - val_accuracy: 0.8847\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.3070 - accuracy: 0.8942 - val_loss: 0.3589 - val_accuracy: 0.8885\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 87s 46ms/step - loss: 0.3028 - accuracy: 0.8982 - val_loss: 0.3718 - val_accuracy: 0.8797\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.3030 - accuracy: 0.8964 - val_loss: 0.3203 - val_accuracy: 0.8942\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.2517 - accuracy: 0.9125 - val_loss: 0.3437 - val_accuracy: 0.8958\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.2296 - accuracy: 0.9200 - val_loss: 0.3445 - val_accuracy: 0.8926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model_loss, combined_model_accuracy = combined_model.evaluate(x_test, y_test)\n",
        "print(f\"Merging model Accuracy: {combined_model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMLSXIIvmmL6",
        "outputId": "9bef544a-3a85-4be3-a3a6-05cf9370452e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3445 - accuracy: 0.8926\n",
            "Merging model Accuracy: 0.8925999999046326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsfccRDkneiQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}